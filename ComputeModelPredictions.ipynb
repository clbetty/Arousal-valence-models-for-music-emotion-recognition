{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOPW6QuERl5r"
      },
      "source": [
        "# Analysis of arousal-valence models for Music Emotion Recognition. Computing model predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, arousal and valence predictions are obtained for chunk 003 using 6 pre-trained ML models, namely:\n",
        "1.   Effnet-Discogs trained on DEAM dataset\n",
        "2.   Effnet-Discogs trained on EmoMusic dataset\n",
        "3.   MusiCNN-MSD trained on DEAM dataset\n",
        "4.   MusiCNN-MSD trained on EmoMusic dataset\n",
        "5.   VGGish-AudioSet trained on DEAM dataset\n",
        "6.   VGGish-AudioSet trained on EmoMusic dataset"
      ],
      "metadata": {
        "id": "T-XvwyHHWKoQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwglmF-qRntF",
        "outputId": "8a19ccab-3af8-4356-9723-2286df328c57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: essentia-tensorflow in /usr/local/lib/python3.7/dist-packages (2.1b6.dev778)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from essentia-tensorflow) (1.21.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from essentia-tensorflow) (1.15.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from essentia-tensorflow) (3.13)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "# Install required dependencies\n",
        "!pip install essentia-tensorflow\n",
        "!pip install pandas "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7l6o0BWdSbWV",
        "outputId": "51e887b6-0c1f-4c80-f229-10ec638e5695"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modify the following paths according to your specific locations."
      ],
      "metadata": {
        "id": "IyxX0MTZW6Dq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9sfT2BS3SdIn"
      },
      "outputs": [],
      "source": [
        "data_root = \"/content/drive/MyDrive/AMPLAB/M1_A1/\"                               # Main path\n",
        "models_root = data_root + \"Emotion-AV-annotation-dataset/essentia-models/\"       # Path where the models are stored\n",
        "audio_root = data_root + \"Emotion-AV-annotation-dataset/audio_chunks/audio.003/\" # Path where the audio samples of chunk 003 are stored"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "42vfoXNiTViE"
      },
      "outputs": [],
      "source": [
        "# Basic imports\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "from essentia import Pool\n",
        "from essentia.standard import (\n",
        "    MonoLoader,\n",
        "    TensorflowPredict,\n",
        "    TensorflowPredictEffnetDiscogs,\n",
        "    TensorflowPredictMusiCNN,\n",
        "    TensorflowPredictVGGish,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "aSxGcNHGiKmQ"
      },
      "outputs": [],
      "source": [
        "def listdirs(rootdir):\n",
        "  'This function returns all the files/folders inside a given directory'\n",
        "  list_subdirectories = []\n",
        "  for file in os.listdir(rootdir):\n",
        "    d = os.path.join(rootdir, file)\n",
        "    list_subdirectories.append(d)\n",
        "  return list_subdirectories"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnaTiearQSM8"
      },
      "source": [
        "## Model predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let's identify all the necessary model files for each type of embedding (EffnetDiscogs, musiCNN-MSD and VGGish-AudioSet) and dataset used for pre-training (DEAM, EmoMusic)."
      ],
      "metadata": {
        "id": "lNR9C8dxx_yP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hEVLQ0bXTAGC"
      },
      "outputs": [],
      "source": [
        "# Effnet-discogs models\n",
        "effnetDiscogs_embeddings_model_path = models_root + \"effnet-discogs-1.pb\"\n",
        "deamEffnetDiscogs_av_model_path = models_root + \"deam-effnet-discogs-1/deam-effnet-discogs-1.pb\"\n",
        "deamEffnetDiscogs_json_model_path = models_root + \"deam-effnet-discogs-1/deam-effnet-discogs-1.json\"\n",
        "emomusicEffnetDiscogs_av_model_path = models_root + \"emomusic-effnet-discogs-1/emomusic-effnet-discogs-1.pb\"\n",
        "emomusicEffnetDiscogs_json_model_path = models_root + \"emomusic-effnet-discogs-1/emomusic-effnet-discogs-1.json\"\n",
        "\n",
        "# MusiCNN-MSD models\n",
        "musiCNN_embeddings_model_path = models_root + \"msd-musicnn-1.pb\"\n",
        "deamMusiCNN_av_model_path = models_root + \"deam-musicnn-msd-1/deam-musicnn-msd-1.pb\"\n",
        "deamMusiCNN_json_model_path = models_root + \"deam-musicnn-msd-1/deam-musicnn-msd-1.json\"\n",
        "emomusicMusiCNN_av_model_path = models_root + \"emomusic-musicnn-msd-1/emomusic-musicnn-msd-1.pb\"\n",
        "emomusicMusiCNN_json_model_path = models_root + \"emomusic-musicnn-msd-1/emomusic-musicnn-msd-1.json\"\n",
        "\n",
        "# VGGish-AudioSet models\n",
        "VGGish_embeddings_model_path = models_root + \"audioset-vggish-3.pb\"\n",
        "deamVGGish_av_model_path = models_root + \"deam-vggish-audioset-1/deam-vggish-audioset-1.pb\"\n",
        "deamVGGish_json_model_path = models_root + \"deam-vggish-audioset-1/deam-vggish-audioset-1.json\"\n",
        "emomusicVGGish_av_model_path = models_root + \"emomusic-vggish-audioset-1/emomusic-vggish-audioset-1.pb\"\n",
        "emomusicVGGish_json_model_path = models_root + \"emomusic-vggish-audioset-1/emomusic-vggish-audioset-1.json\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YJRQecAZoY7"
      },
      "source": [
        "### Effnet-discogs models setting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B02FUNYLZv4a"
      },
      "source": [
        "Let's define now the parameters and model instantiations for the Effnet-Discogs embedding. \n",
        "\n",
        "The patch_size defines the number of melspectrogram frames the model needs to return an embedding vector. Effnet model needs 128 frames and each frame is extracted with a 256-samples hopsize. That's why the receptive field of Effnet is 2-seconds, 128 * 256/ 16000 ≈ 2 seconds, and it differs of MusiCNN which utilizes 187 frames (3-seconds).\n",
        "\n",
        "The patch_hop_size defines the number of feature frames in between successive embedding. It defines the time interval analysed at each embedding vector and it can vary for each model. Effnet applies 64 patches, close to 1-seconds (64 * 256 / 16000), whereas MusiCNN applies 1.5-seconds (93 * 256/ 16000 ≈ 1.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XhuazZa_ZnTb"
      },
      "outputs": [],
      "source": [
        "patch_size_effnetDiscogs = 128\n",
        "patch_hop_size_effnetDiscogs = patch_size_effnetDiscogs // 2\n",
        "\n",
        "input_layer_effnetDiscogs = \"melspectrogram\"\n",
        "output_layer_effnetDiscogs = \"onnx_tf_prefix_BatchNormalization_496/add_1\"\n",
        "\n",
        "embeddings_model_effnetDiscogs = TensorflowPredictEffnetDiscogs(\n",
        "                                  graphFilename=effnetDiscogs_embeddings_model_path,\n",
        "                                  input=input_layer_effnetDiscogs,\n",
        "                                  output=output_layer_effnetDiscogs,\n",
        "                                  patchSize=patch_size_effnetDiscogs,\n",
        "                                  patchHopSize=patch_hop_size_effnetDiscogs,\n",
        "                                  )\n",
        "\n",
        "metadata_deamEffnetDiscogs = json.load(open(deamEffnetDiscogs_json_model_path, \"r\"))\n",
        "input_layer_deamEffnetDiscogs = metadata_deamEffnetDiscogs[\"schema\"][\"inputs\"][0][\"name\"]\n",
        "output_layer_deamEffnetDiscogs = metadata_deamEffnetDiscogs[\"schema\"][\"outputs\"][0][\"name\"]\n",
        "av_deamEffnetDiscogs_model = TensorflowPredict(\n",
        "                              graphFilename=deamEffnetDiscogs_av_model_path,\n",
        "                              inputs=[input_layer_deamEffnetDiscogs],\n",
        "                              outputs=[output_layer_deamEffnetDiscogs],\n",
        "                              )\n",
        "\n",
        "metadata_emomusicEffnetDiscogs = json.load(open(emomusicEffnetDiscogs_json_model_path, \"r\"))\n",
        "input_layer_emomusicEffnetDiscogs = metadata_emomusicEffnetDiscogs[\"schema\"][\"inputs\"][0][\"name\"]\n",
        "output_layer_emomusicEffnetDiscogs = metadata_emomusicEffnetDiscogs[\"schema\"][\"outputs\"][0][\"name\"]\n",
        "av_emomusicEffnetDiscogs_model = TensorflowPredict(\n",
        "                                  graphFilename=emomusicEffnetDiscogs_av_model_path,\n",
        "                                  inputs=[input_layer_emomusicEffnetDiscogs],\n",
        "                                  outputs=[output_layer_emomusicEffnetDiscogs],\n",
        "                                  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXZzAjzbblBL"
      },
      "source": [
        "### MusiCNN-MSD models setting"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now define the parameters and model instantiations for the MusiCNN-MSD embedding."
      ],
      "metadata": {
        "id": "R_JRjUATYX8s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6ERhNOZbbkKb"
      },
      "outputs": [],
      "source": [
        "# Embeddings model\n",
        "input_layer_musiCNN = \"model/Placeholder\"\n",
        "output_layer_musiCNN = \"model/dense/BiasAdd\"\n",
        "\n",
        "# Instantiate the embeddings model\n",
        "# (we can instantiate once and then compute on many different inputs).\n",
        "embeddings_model_musiCNN = TensorflowPredictMusiCNN(\n",
        "                            graphFilename=musiCNN_embeddings_model_path,\n",
        "                            input=input_layer_musiCNN,\n",
        "                            output=output_layer_musiCNN,\n",
        "                          )\n",
        "\n",
        "metadata_deamMusiCNN = json.load(open(deamMusiCNN_json_model_path, \"r\"))\n",
        "input_layer_deamMusiCNN = metadata_deamMusiCNN[\"schema\"][\"inputs\"][0][\"name\"]\n",
        "output_layer_deamMusiCNN = metadata_deamMusiCNN[\"schema\"][\"outputs\"][0][\"name\"]\n",
        "av_deamMusiCNN_model = TensorflowPredict(\n",
        "                        graphFilename=deamMusiCNN_av_model_path,\n",
        "                        inputs=[input_layer_deamMusiCNN],\n",
        "                        outputs=[output_layer_deamMusiCNN],\n",
        "                        )\n",
        "\n",
        "metadata_emomusicMusiCNN = json.load(open(emomusicMusiCNN_json_model_path, \"r\"))\n",
        "input_layer_emomusicMusiCNN = metadata_emomusicMusiCNN[\"schema\"][\"inputs\"][0][\"name\"]\n",
        "output_layer_emomusicMusiCNN = metadata_emomusicMusiCNN[\"schema\"][\"outputs\"][0][\"name\"]\n",
        "av_emomusicMusiCNN_model = TensorflowPredict(\n",
        "                          graphFilename=emomusicMusiCNN_av_model_path,\n",
        "                          inputs=[input_layer_emomusicMusiCNN],\n",
        "                          outputs=[output_layer_emomusicMusiCNN],\n",
        "                          )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y64_rQbQfspz"
      },
      "source": [
        "### VGGish-AudioSet models setting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOMSKnVRf5Cw"
      },
      "source": [
        "Finally, let's define the parameters and instantiate the models for the VGGish-AudioSet embedding. VGGish-AudioSet works in time domain, it doesn't need to specify patch_size and patch_hop_size, only output_layer name."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "hrPsCRiwb3hy"
      },
      "outputs": [],
      "source": [
        "output_layer_VGGish = \"model/vggish/embeddings\"\n",
        "\n",
        "embeddings_model_VGGish = TensorflowPredictVGGish(\n",
        "                          graphFilename=VGGish_embeddings_model_path,\n",
        "                          output=output_layer_VGGish,\n",
        "                          )\n",
        "\n",
        "metadata_deamVGGish = json.load(open(deamVGGish_json_model_path, \"r\"))\n",
        "input_layer_deamVGGish = metadata_deamVGGish[\"schema\"][\"inputs\"][0][\"name\"]\n",
        "output_layer_deamVGGish = metadata_deamVGGish[\"schema\"][\"outputs\"][0][\"name\"]\n",
        "av_deamVGGish_model = TensorflowPredict(\n",
        "                      graphFilename=deamVGGish_av_model_path,\n",
        "                      inputs=[input_layer_deamVGGish],\n",
        "                      outputs=[output_layer_deamVGGish],\n",
        "                      )\n",
        "\n",
        "metadata_emomusicVGGish = json.load(open(emomusicVGGish_json_model_path, \"r\"))\n",
        "input_layer_emomusicVGGish = metadata_emomusicVGGish[\"schema\"][\"inputs\"][0][\"name\"]\n",
        "output_layer_emomusicVGGish = metadata_emomusicVGGish[\"schema\"][\"outputs\"][0][\"name\"]\n",
        "av_emomusicVGGish_model = TensorflowPredict(\n",
        "                          graphFilename=emomusicVGGish_av_model_path,\n",
        "                          inputs=[input_layer_emomusicVGGish],\n",
        "                          outputs=[output_layer_emomusicVGGish],\n",
        "                          )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyftscuug98e"
      },
      "source": [
        "### Compute predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJtRQOUqhFcn"
      },
      "source": [
        "Let's create a Pandas DataFrame to store all the predictions of the different models for all the audio recordings. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "FQtUWQ-Gnx39"
      },
      "outputs": [],
      "source": [
        "columns = [\"Audio Filename\", \"Valence DEAM-Effnet-Discogs\", \"Arousal DEAM-Effnet-Discogs\", \n",
        "           \"Valence EmoMusic-Effnet-Discogs\", \"Arousal EmoMusic-Effnet-Discogs\", \n",
        "           \"Valence DEAM-MusiCNN\", \"Arousal DEAM-MusiCNN\", \n",
        "           \"Valence EmoMusic-MusiCNN\", \"Arousal EmoMusic-MusiCNN\",\n",
        "           \"Valence DEAM-VGGish\", \"Arousal DEAM-VGGish\",\n",
        "           \"Valence EmoMusic-VGGish\", \"Arousal EmoMusic-VGGish\"]\n",
        "df = pd.DataFrame(columns=columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now loop through all the audio files to extract the embeddings using the 3 different types, and then compute predictions using the 6 different pre-trained models. In order to avoid loading too many times the same audio file, all the models are run each time an audio is loaded in the loop."
      ],
      "metadata": {
        "id": "Bb9ue16rY0XM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQh8CofIg9PA",
        "outputId": "ea6a1267-d3e8-4beb-c8da-bf91aeffb1d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing sound with id 0Y3lmI2xyEOjJXld4zEo5y [1/300]\n",
            "Processing sound with id 0l8tol0rUlorDx5qpxQslV [2/300]\n",
            "Processing sound with id 0lE400SRtjUmLk37qkt77q [3/300]\n",
            "Processing sound with id 0lTQgId3gmoTrrCad2YjpT [4/300]\n",
            "Processing sound with id 0lhDwEGQ6IDlGrko5T7Ei2 [5/300]\n",
            "Processing sound with id 3BucMqBqIR5Aw7MrUkF00y [6/300]\n",
            "Processing sound with id 17CHY0FoOgypamXGpk0Kqj [7/300]\n",
            "Processing sound with id 17E5kYLd1yrnzndzn4Xovp [8/300]\n",
            "Processing sound with id 0NYVB11fk0kBalG46SxSTR [9/300]\n",
            "Processing sound with id 0NJWhm3hUwIZSy5s0TGJ8q [10/300]\n",
            "Processing sound with id 0JHz6TOCIsxSqenueJUmts [11/300]\n",
            "Processing sound with id 77DRSxsaUoQSaTK0UI4I0a [12/300]\n",
            "Processing sound with id 77lxwJmO8GfWk2LdpirwEf [13/300]\n",
            "Processing sound with id 77tBTw4wbI5RmvZuJ86q4I [14/300]\n",
            "Processing sound with id 19PKMOoh2Rra8T50wrkq1X [15/300]\n",
            "Processing sound with id 1A1hXivNLAWyNf6pVysqzm [16/300]\n",
            "Processing sound with id 2ZrCLJz5UGbJCW2JK2OgkK [17/300]\n",
            "Processing sound with id 6O3PRnABuZ8wdhOIzggfX7 [18/300]\n",
            "Processing sound with id 0jFfXI7V7Wz24quphghPjx [19/300]\n",
            "Processing sound with id 1igX49W93rcpYiYNKggDNx [20/300]\n",
            "Processing sound with id 5TyfUXhl7AShsLjj9MEKtg [21/300]\n",
            "Processing sound with id 7cnYu5p5nGWnN8MDi8gzI3 [22/300]\n",
            "Processing sound with id 143HujryNbnIzNV85jkW8a [23/300]\n",
            "Processing sound with id 0GvhxFWYe7preIkRFwee78 [24/300]\n",
            "Processing sound with id 1nOjBqRjDq2ETiyvughrot [25/300]\n",
            "Processing sound with id 5EMTuiSD6NTqnQOmWgNQxg [26/300]\n",
            "Processing sound with id 2LUvOQEoHLBqewAEd20hHt [27/300]\n",
            "Processing sound with id 5yyoZY5JWtqpQyTf0qjgyU [28/300]\n",
            "Processing sound with id 7v5zr1r0ft1LX2pIjHXopK [29/300]\n",
            "Processing sound with id 2VX8peEoA0gx5xSF4uuCDS [30/300]\n",
            "Processing sound with id 2V9zvMiYJAB06S8LeN89fr [31/300]\n",
            "Processing sound with id 7gmLJK3f06F0nEQPKpgw13 [32/300]\n",
            "Processing sound with id 5qOTBbDByTYPr6cd1jNIpy [33/300]\n",
            "Processing sound with id 4IMyXN5fxdQib60dcLBwza [34/300]\n",
            "Processing sound with id 4CHdGJVDGocslGo0Gg3Pr9 [35/300]\n",
            "Processing sound with id 4ChvDvxokx0xrf2LMot73r [36/300]\n",
            "Processing sound with id 0bWBwgthq5MszvRvUSBGSM [37/300]\n",
            "Processing sound with id 6SqNM0R780HztwePWJFMEi [38/300]\n",
            "Processing sound with id 79N9aDPDWEWND2oySCsTTa [39/300]\n",
            "Processing sound with id 79LFkOkzJNziCVuRhPfZA6 [40/300]\n",
            "Processing sound with id 2x9xkTgTa8BodQyKJ4c1bd [41/300]\n",
            "Processing sound with id 3KyMDgZ2FewZ6XyHuZWs0K [42/300]\n",
            "Processing sound with id 3KibbsOmFYAeJThZ2nxT3e [43/300]\n",
            "Processing sound with id 3MsD0RrlQb1OoPFInlQoJy [44/300]\n",
            "Processing sound with id 1LMiP1N3TVxC6lprrXkdR7 [45/300]\n",
            "Processing sound with id 4e0yKeT7bzGAGtojzb7kKK [46/300]\n",
            "Processing sound with id 4EbAftNM732UGLF8gmIIsX [47/300]\n",
            "Processing sound with id 1bz1ODiHBopRFAHTOjXlbs [48/300]\n",
            "Processing sound with id 2dqTbZNQeNL1AcXfWnqFcG [49/300]\n",
            "Processing sound with id 2dQCpor5f7eEMEmhaFID4Q [50/300]\n",
            "Processing sound with id 2dgjqBW7kpT5v7nPTlKaiB [51/300]\n",
            "Processing sound with id 2yMfDwie0nTQDpyMGDWwPD [52/300]\n",
            "Processing sound with id 44NYkYW8Do5aUwVHioEJjT [53/300]\n",
            "Processing sound with id 45XFisTHb1wI5MtJztFYsu [54/300]\n",
            "Processing sound with id 08QbOsku2EOiuuUm3OH28J [55/300]\n",
            "Processing sound with id 08pVm2BCyMSevBLXYLysqi [56/300]\n",
            "Processing sound with id 5sCNS9a5UWmKCtUUu6W5uD [57/300]\n",
            "Processing sound with id 4t311U33AbGjloBf67KGBs [58/300]\n",
            "Processing sound with id 4t0UsYzmmmZRMTWn77jiGF [59/300]\n",
            "Processing sound with id 0c3vUiksPi7mXsoM522Gf9 [60/300]\n",
            "Processing sound with id 0cj9AHHdO4iRDR2hVeOyAR [61/300]\n",
            "Processing sound with id 1eyzqe2QqGZUmfcPZtrIyt [62/300]\n",
            "Processing sound with id 3mHCQ9DIYjX0NAO6wnqzaJ [63/300]\n",
            "Processing sound with id 0rtwHkepURDqxAdUxWXykm [64/300]\n",
            "Processing sound with id 0rQmjNSVZ5GhCqGnukSrhK [65/300]\n",
            "Processing sound with id 0IrUz3oc0aSfF5fVQUnVUQ [66/300]\n",
            "Processing sound with id 58LxKK9f7TvDbOsKphZPxd [67/300]\n",
            "Processing sound with id 58JcKCPKsLnBadxsDqNqEn [68/300]\n",
            "Processing sound with id 7wZa5nV5BvTwSfRu36esIk [69/300]\n",
            "Processing sound with id 3hmmlW9KwLdkP01j7nqhRn [70/300]\n",
            "Processing sound with id 3hTzIZaKy1GVOJvPYpdl4Y [71/300]\n",
            "Processing sound with id 078jgASD7mWkJDAfLvFYwl [72/300]\n",
            "Processing sound with id 4v2pTkXsKknPOitU7vvzvw [73/300]\n",
            "Processing sound with id 3cvqLU5jEYa1mZStxzFpdW [74/300]\n",
            "Processing sound with id 3ctVNvIQADSeclquk9fStY [75/300]\n",
            "Processing sound with id 7ktsTO95YywAksR984DvQO [76/300]\n",
            "Processing sound with id 68B3urp2uXgEDenOfqhdQi [77/300]\n",
            "Processing sound with id 6FUXgvzbMrMCzAuYGIiGIl [78/300]\n",
            "Processing sound with id 6FGfIODiIJhZzYtDJ2jO1c [79/300]\n",
            "Processing sound with id 33x3cy2E42Xg0xWOxZB8M7 [80/300]\n",
            "Processing sound with id 33lz1O0dCOcMZVWnmZG65i [81/300]\n",
            "Processing sound with id 0HvwaNR0TYLiIwe6WzZ8Pa [82/300]\n",
            "Processing sound with id 6ad9IwfoJR5sf2ehNw5vx2 [83/300]\n",
            "Processing sound with id 0uDDwQW7RjDvGZXKryHshr [84/300]\n",
            "Processing sound with id 7tcLPSrqwfYtSYmIVLu8dJ [85/300]\n",
            "Processing sound with id 2wWlOixgIosfeYZEQyhsaO [86/300]\n",
            "Processing sound with id 5P97xlvOl6IadKTLVId5ap [87/300]\n",
            "Processing sound with id 1PF4kAUHKTydD73icSVno1 [88/300]\n",
            "Processing sound with id 1PiM5snP1x9HKFnqx0Bzdf [89/300]\n",
            "Processing sound with id 46mjoNCQ3EifsDnd6dwqRD [90/300]\n",
            "Processing sound with id 46UwWvYZzHeJaGGOW38C16 [91/300]\n",
            "Processing sound with id 46mNqoWLxrEv22VeB949jf [92/300]\n",
            "Processing sound with id 46MqtjQLk79eOkbgfPU8IX [93/300]\n",
            "Processing sound with id 1GqbE5C00KPPiLab8SIC5C [94/300]\n",
            "Processing sound with id 4shU3N2Yc95zvb3j4pwjDr [95/300]\n",
            "Processing sound with id 39RS1hXgRE02HJG9cBa9SC [96/300]\n",
            "Processing sound with id 39lSeqnyjZJejRuaREfyLL [97/300]\n",
            "Processing sound with id 2RXp5EdKB8RFNOEodPxdTv [98/300]\n",
            "Processing sound with id 0PLQrSA6N7EofEPxu4Sg0U [99/300]\n",
            "Processing sound with id 7s1NgVP7Mx9bBpyKeSnsYO [100/300]\n",
            "Processing sound with id 73NQ9fWD3g74wsUh5LTdfF [101/300]\n",
            "Processing sound with id 4LdhCfyICUiSGDodEtSi7n [102/300]\n",
            "Processing sound with id 2Y0Zb2iYC5mys5z44zjkNM [103/300]\n",
            "Processing sound with id 6xiDbah5fuoPV4Z5qQk4Nh [104/300]\n",
            "Processing sound with id 59uTpQjGQynHLpKtVyJn0I [105/300]\n",
            "Processing sound with id 4DS3ZiDI4JsSYCtD1CwL6u [106/300]\n",
            "Processing sound with id 4DNgnLds0wF7wWoQvQj6La [107/300]\n",
            "Processing sound with id 1gNgqMrQ4Fy8vhc4PdDvAP [108/300]\n",
            "Processing sound with id 1g8Tju9Ev4fjUktqLRTmMj [109/300]\n",
            "Processing sound with id 1yrRrnCtqG2ICItTVMdXoB [110/300]\n",
            "Processing sound with id 1yMfoWCHtOEH2b5LzzPyJF [111/300]\n",
            "Processing sound with id 1ywbZ7FfMe6C4vmm7eMId7 [112/300]\n",
            "Processing sound with id 4GZjvcQKAwHhjMyWVld345 [113/300]\n",
            "Processing sound with id 4Go9AgEPTBVfGOZ8Rrlosj [114/300]\n",
            "Processing sound with id 6pHCJmx9FXnMwEqB0LWUEH [115/300]\n",
            "Processing sound with id 51iB6H3CQEmaaaKkmhmwum [116/300]\n",
            "Processing sound with id 2rG2A0PpcvnWDed8CaN2x5 [117/300]\n",
            "Processing sound with id 7aya3eV6qcLpxAfRrLMnWj [118/300]\n",
            "Processing sound with id 7aENwq13lwx4TLLNRDxr5P [119/300]\n",
            "Processing sound with id 3XUeZXB9fVrsrSA89lEiBp [120/300]\n",
            "Processing sound with id 7xkOxuOZrD1pKYHKUatSwX [121/300]\n",
            "Processing sound with id 7xHrqNdRTjVmvualewApyl [122/300]\n",
            "Processing sound with id 7onMf0QvWgRba2MRxG27yj [123/300]\n",
            "Processing sound with id 1uZR7PBZsK4zzIVb9wLa6g [124/300]\n",
            "Processing sound with id 2iBBgPKHPOdnS5bHlWPKri [125/300]\n",
            "Processing sound with id 0dnyegp8zG1ZFqhjqx6zw8 [126/300]\n",
            "Processing sound with id 7GQ65Z5AKL45QSfPudqMcE [127/300]\n",
            "Processing sound with id 4p8qxFrOm4frxZqQWQTIQF [128/300]\n",
            "Processing sound with id 4pGIwsD4Zbb6E6WFbyXcqL [129/300]\n",
            "Processing sound with id 1rUM9s818ewNfP57q8U1Cl [130/300]\n",
            "Processing sound with id 4OV6GtRryDhYWwVQrfYMLq [131/300]\n",
            "Processing sound with id 2A57iSwKqW11Dl3u11SMPS [132/300]\n",
            "Processing sound with id 2ABXKIG0eCgk9wIS91i8Ao [133/300]\n",
            "Processing sound with id 2A0kGn4bBGMQQaapRTHWe6 [134/300]\n",
            "Processing sound with id 1VWYKR91K0WYMxyBHNaYxt [135/300]\n",
            "Processing sound with id 49ke1qwOtVOkc37k41wN9f [136/300]\n",
            "Processing sound with id 49ty0lBIjB1YQ9oNU7JadW [137/300]\n",
            "Processing sound with id 3VRSHMQhc0ea5ieH9jFVrb [138/300]\n",
            "Processing sound with id 0VqXZeSmSu7SwKWAn1NUKA [139/300]\n",
            "Processing sound with id 11E6QPniTlPYpokkRwW8Al [140/300]\n",
            "Processing sound with id 4Z7QBt3jUFs1vfER8RRQuN [141/300]\n",
            "Processing sound with id 4nZQotVbb81u2foJ8hb9nw [142/300]\n",
            "Processing sound with id 4nWuBetUupWLaI6y1wPPL3 [143/300]\n",
            "Processing sound with id 6MzIBGCg0m1GtNggLPM31h [144/300]\n",
            "Processing sound with id 0nB6tFPHN5IF0LQ7glMHW3 [145/300]\n",
            "Processing sound with id 1BdtUjQmkvRTTUVySRuK4e [146/300]\n",
            "Processing sound with id 7q2kHP1fs5FMJgzVjSRf0q [147/300]\n",
            "Processing sound with id 0iJEGlU72MMwbPf8igQsVI [148/300]\n",
            "Processing sound with id 5tmr8APgZgBwhxhkNzAQ4l [149/300]\n",
            "Processing sound with id 2WgNlycdYeO9sP9z3ufsjH [150/300]\n",
            "Processing sound with id 2WUjG575gTewbJaKZRuAFy [151/300]\n",
            "Processing sound with id 7ELg58IHgSF4lRySlYdFX0 [152/300]\n",
            "Processing sound with id 7ENJrQROroKjNHTazh7Trb [153/300]\n",
            "Processing sound with id 7E7I138eFwEcAik295zVtR [154/300]\n",
            "Processing sound with id 47qvke9uksVrfspdBZq3GJ [155/300]\n",
            "Processing sound with id 47YVkgrlWHlffZ23TtV1se [156/300]\n",
            "Processing sound with id 5cS8AioMBXGgN2j4WuG7Jz [157/300]\n",
            "Processing sound with id 5xulhS4L3ASnX8nno7M5jw [158/300]\n",
            "Processing sound with id 1wzlZc4DoezFQn0rAwtZ64 [159/300]\n",
            "Processing sound with id 1wx6JALNy9KXwndVziEUKw [160/300]\n",
            "Processing sound with id 3pkqq8JV30MoMTI6n6XhVK [161/300]\n",
            "Processing sound with id 3ptJ7m0qwmSb6699oXLKL9 [162/300]\n",
            "Processing sound with id 3peL9cqmPNF73Wn8faWHMy [163/300]\n",
            "Processing sound with id 343ySUa7BIhKTLOFgVzzYc [164/300]\n",
            "Processing sound with id 34Z8N55sBaI0DNAqk8U5N8 [165/300]\n",
            "Processing sound with id 2T0aAtVXRDyD0nbK4tzArv [166/300]\n",
            "Processing sound with id 6ejDDdghjgMZTJs9pTzk33 [167/300]\n",
            "Processing sound with id 5Jc5FzzI9xN8cYDiKlKpr1 [168/300]\n",
            "Processing sound with id 4f1QbCjIAgQwnf7ms9NXWx [169/300]\n",
            "Processing sound with id 18XhpMPsd4oeX6lQETPeaU [170/300]\n",
            "Processing sound with id 183gI3hEvjHAL1RlvTblZz [171/300]\n",
            "Processing sound with id 0wz31AWD9yC0mZeF4t9pcX [172/300]\n",
            "Processing sound with id 01NHK6TUBtTAtBNA39FH6g [173/300]\n",
            "Processing sound with id 60w5eL1G4Or7LlTSrR5r8a [174/300]\n",
            "Processing sound with id 6qEMgZTY49sdFi7x755afY [175/300]\n",
            "Processing sound with id 2McQQA5nCLVL0XvzcxWhFC [176/300]\n",
            "Processing sound with id 2eqr7DrwqPTzamWZVXxTZi [177/300]\n",
            "Processing sound with id 3Z40DcSjnyDg2d8qG6jP4V [178/300]\n",
            "Processing sound with id 2QjAWSIREtRLTmRv0p2oe4 [179/300]\n",
            "Processing sound with id 2QjmxeV1c6tXttgEBFeeRM [180/300]\n",
            "Processing sound with id 10Of4lAUPlbpicWFB0ZnIp [181/300]\n",
            "Processing sound with id 3riz6wqLBa0rWNYDFs93ND [182/300]\n",
            "Processing sound with id 32j4mGWxHedWUTPKXJUJkS [183/300]\n",
            "Processing sound with id 32PD9utT52FW6a8SrV4WBW [184/300]\n",
            "Processing sound with id 7eO7YYU5gxeHUWYdhVu1ix [185/300]\n",
            "Processing sound with id 7eizKw48l12EVbAqgqv5JB [186/300]\n",
            "Processing sound with id 78dwpnPXpLkPW67Xk8cLKk [187/300]\n",
            "Processing sound with id 15LhiWzrEB8vxTAUrYDhET [188/300]\n",
            "Processing sound with id 4SbB5aNkAo0eyR2PGSp8a5 [189/300]\n",
            "Processing sound with id 4Qw9AIQsusSdvEcO0MuOv3 [190/300]\n",
            "Processing sound with id 1RDnckI3aDh19h9TJAUm3N [191/300]\n",
            "Processing sound with id 5VqPvzYua29fkUejZTdW2z [192/300]\n",
            "Processing sound with id 5WlZhRhLqTDxbhLGftSd6l [193/300]\n",
            "Processing sound with id 0RSPtnexlPUm2gFecq6swu [194/300]\n",
            "Processing sound with id 5KNuHsIeFtD0oukst77hBi [195/300]\n",
            "Processing sound with id 5KKA2xfuxPgOpSlCuBpOAQ [196/300]\n",
            "Processing sound with id 2DTUoqKx7DhtJOIIZZzYsV [197/300]\n",
            "Processing sound with id 4YtoipFgf4k0AfD17ZfD5X [198/300]\n",
            "Processing sound with id 4YMPdjjBjHFx5Jb8r2tRua [199/300]\n",
            "Processing sound with id 0KwNTV2sJWjUSBF9kJkdcP [200/300]\n",
            "Processing sound with id 6hpXcN0xlqicCBqdKQUnIe [201/300]\n",
            "Processing sound with id 1WV5rOR72Wnned6fbusF0J [202/300]\n",
            "Processing sound with id 2GtgbtCgTunjRgTvuRBsRp [203/300]\n",
            "Processing sound with id 6j93BOiE0cKmczhaXMoudl [204/300]\n",
            "Processing sound with id 5dg3UDruST8ro3QGWpEDeu [205/300]\n",
            "Processing sound with id 29QgHKWCo324ii8otbB0po [206/300]\n",
            "Processing sound with id 6z6mAQsKBvp9xPTm149Cvq [207/300]\n",
            "Processing sound with id 27IYG1JrNewpEyyV5UnKZ1 [208/300]\n",
            "Processing sound with id 53EvebEqnYnlQ3Rl6Ar1bu [209/300]\n",
            "Processing sound with id 2Xu21AeNdt8rLShMYgYwpU [210/300]\n",
            "Processing sound with id 4PgXQ2ld1xWuinf5YmMolQ [211/300]\n",
            "Processing sound with id 5DkFpeYPwQes4a9YE3UUdd [212/300]\n",
            "Processing sound with id 5DapY2iD54dh0PwfPbx1RM [213/300]\n",
            "Processing sound with id 5DhPPiULuuXllyVd3T8ZaN [214/300]\n",
            "Processing sound with id 7nArT01M30dHx2hXlp38K3 [215/300]\n",
            "Processing sound with id 7nQupMTASPyqh7K4KMMty9 [216/300]\n",
            "Processing sound with id 7nc7mlSdWYeFom84zZ8Wr8 [217/300]\n",
            "Processing sound with id 6iiNLPahws8aIJVHZ2WXRC [218/300]\n",
            "Processing sound with id 1li0bEaF6w4wh6tTX8axPI [219/300]\n",
            "Processing sound with id 1DCyjMo53EYmSKRakLX4Qc [220/300]\n",
            "Processing sound with id 0tKWVnnCD6rmtSBIR7AiE4 [221/300]\n",
            "Processing sound with id 4o6NJIrxUu3FZrGcMCw6ij [222/300]\n",
            "Processing sound with id 4Tpq2LKCwOyAJlSHNR4iPk [223/300]\n",
            "Processing sound with id 5IZIRyq2lhi3W91NLDd6Oz [224/300]\n",
            "Processing sound with id 57EuuAQJrXOVeAdII7zhMb [225/300]\n",
            "Processing sound with id 4N9kQdAcmIVUkO8X4K3HCO [226/300]\n",
            "Processing sound with id 068kwDUkikmINIQvfDMdKw [227/300]\n",
            "Processing sound with id 2UVPNfmTx2C27Py3z5r9RC [228/300]\n",
            "Processing sound with id 2UsEahJ2lpbBjguCfLHPP4 [229/300]\n",
            "Processing sound with id 3xEl5TknncBXeRkJ6btZqW [230/300]\n",
            "Processing sound with id 5NSSeFthY3wqM8gsen1gWL [231/300]\n",
            "Processing sound with id 6weHLuzNm4SRH2Fpf1uLGu [232/300]\n",
            "Processing sound with id 2qzRf1nn7hFpVod2PHhqB3 [233/300]\n",
            "Processing sound with id 6sXbpvH7jtU2gQFiiZ5aol [234/300]\n",
            "Processing sound with id 0sALHeGJRuARAw6jWuRfF3 [235/300]\n",
            "Processing sound with id 4XQCDyqgkGzwwdut5V7tdp [236/300]\n",
            "Processing sound with id 2EPi4anyxVjKTcJwPtntjM [237/300]\n",
            "Processing sound with id 55mCj2LMr3csP88djkFpPN [238/300]\n",
            "Processing sound with id 54WCcYlzRgr1PydRIOAqlF [239/300]\n",
            "Processing sound with id 5eJJOdNwwqCOChRnamKor3 [240/300]\n",
            "Processing sound with id 7Bxsyzl3Y1LAeWb5ItbIAb [241/300]\n",
            "Processing sound with id 3Nw2j8vvelMdowOSo2K2Bs [242/300]\n",
            "Processing sound with id 3NJOkeaVMwqmzAGHGx4k29 [243/300]\n",
            "Processing sound with id 6LysPLhdNKyT1dhV3bnVuH [244/300]\n",
            "Processing sound with id 4z3G635lvJWGsQKmCTtMZP [245/300]\n",
            "Processing sound with id 1ZRcHeXCAVacsTQbFbuA0w [246/300]\n",
            "Processing sound with id 1sNZoN5Nj0Z7dXUizHNi2L [247/300]\n",
            "Processing sound with id 2hIacvX7e5s1AKb4zOh0pc [248/300]\n",
            "Processing sound with id 0Qk5uOiuYeZkcSFaGu9oDi [249/300]\n",
            "Processing sound with id 2mrGbJrpRyRFDpj2HSeDh5 [250/300]\n",
            "Processing sound with id 5vrBjHR618nUnz8XFfVFoY [251/300]\n",
            "Processing sound with id 3Iutwimw1myD09IjXITuhg [252/300]\n",
            "Processing sound with id 4U2EixxDvgzSpZt042KEjI [253/300]\n",
            "Processing sound with id 5fIzsXrLeaHkxLqrHKc1Xr [254/300]\n",
            "Processing sound with id 0ASvZIiB2Ml32DlUhfaOhx [255/300]\n",
            "Processing sound with id 7f1yOiKyYUasPVR4LvsCVT [256/300]\n",
            "Processing sound with id 7ff9IBgVwy779rg5ZMOIHZ [257/300]\n",
            "Processing sound with id 6KH5uqmb88VmciRhHKj52Z [258/300]\n",
            "Processing sound with id 6npkmaGltaX4s4FC8s4KHH [259/300]\n",
            "Processing sound with id 7pFjc2VFPv8LRnYfNHE8iS [260/300]\n",
            "Processing sound with id 7ps7z3HNmjHWNS9kzNjle2 [261/300]\n",
            "Processing sound with id 02MDVGgVJbKJ6PsAG6793p [262/300]\n",
            "Processing sound with id 4H17zKB1wyykTf4qAWVLZg [263/300]\n",
            "Processing sound with id 0WGmB12qGPK56sjoqX6viN [264/300]\n",
            "Processing sound with id 5jqgjCCAvc3qdgy4NYCnIu [265/300]\n",
            "Processing sound with id 5jgeoj4zIu3haLuQVjBrbi [266/300]\n",
            "Processing sound with id 5CT2VZZjAUBSYyn65P2zHt [267/300]\n",
            "Processing sound with id 5CLDZpfRv5NQxi1bvu4Pmn [268/300]\n",
            "Processing sound with id 52VGQZSdC985CXY3n0i7KZ [269/300]\n",
            "Processing sound with id 4l6CnxuPdcNvwjeYc0CvAN [270/300]\n",
            "Processing sound with id 4rcksONsjJS3l9HLJheAdD [271/300]\n",
            "Processing sound with id 3Uk7MAe0uB7S11MDMuBfst [272/300]\n",
            "Processing sound with id 71MUAfcaGbPtVxemhAC4bo [273/300]\n",
            "Processing sound with id 3ytUgxZj1EYHb8zlk5VKk6 [274/300]\n",
            "Processing sound with id 3yCYQ0uzJyX0GwJoF3QvAe [275/300]\n",
            "Processing sound with id 3yKDTSL7IbEGJy7pm8tSgK [276/300]\n",
            "Processing sound with id 3y8DxOuZnp8C0SLhzWFRNJ [277/300]\n",
            "Processing sound with id 1oSIsS2Wfx5hQiB2WqorrT [278/300]\n",
            "Processing sound with id 3SVE6robjmmhvsN22UIIl5 [279/300]\n",
            "Processing sound with id 2gDeV5YfzTo9TkyOmhrRK0 [280/300]\n",
            "Processing sound with id 30YGNU3qLzdJ4dQXF4ZgUo [281/300]\n",
            "Processing sound with id 30kU9ykTiTKHsyb8OiKe6F [282/300]\n",
            "Processing sound with id 1IM5em8ceA9Ukorn9xf19w [283/300]\n",
            "Processing sound with id 2psrPqL1UKkVomwgeWZzFj [284/300]\n",
            "Processing sound with id 2pn2StUamiL479IvDxib7P [285/300]\n",
            "Processing sound with id 3PjWpRGkOrbp2epH9871Vn [286/300]\n",
            "Processing sound with id 0vftWnxkkTLK611M5R31rB [287/300]\n",
            "Processing sound with id 0v1Yg2zOk3t0YoW8NWsgWt [288/300]\n",
            "Processing sound with id 0ZVcDEK0peds7MKBRIqnIV [289/300]\n",
            "Processing sound with id 2Jyeb7OASnoTLimeuoQ6rr [290/300]\n",
            "Processing sound with id 6J9UUQSQ9Vm9fh6vZgLlzu [291/300]\n",
            "Processing sound with id 2PxGGRmj5yunYdNF2Ud2vm [292/300]\n",
            "Processing sound with id 4mEyJLA4OhmS6VNo5GxtEm [293/300]\n",
            "Processing sound with id 4mmh5f2kfslEezzBAfOeht [294/300]\n",
            "Processing sound with id 6E5nupnnwz0PdA0fTGYp57 [295/300]\n",
            "Processing sound with id 6EDy6U8aPJ8H0ThnRlQLoh [296/300]\n",
            "Processing sound with id 6ECBueopn5ikxPo2fMBsvC [297/300]\n",
            "Processing sound with id 6EYCCC9yGn1hZBHLPslNl3 [298/300]\n",
            "Processing sound with id 6E10rK35nbpf8872ZBl93h [299/300]\n",
            "Processing sound with id 3JpWsHRsEXBTNumroUGlXb [300/300]\n"
          ]
        }
      ],
      "source": [
        "num_audio = 1\n",
        "audio_folders = listdirs(audio_root)\n",
        "for folder in audio_folders:\n",
        "  audio_paths = listdirs(folder + \"/\")\n",
        "  for audio_path in audio_paths:\n",
        "    audio_filename = audio_path.split('/')[-1].split('.')[0]\n",
        "    print('Processing sound with id {0} [{1}/300]'.format(audio_filename, num_audio))\n",
        "    audio = MonoLoader(filename=audio_path, sampleRate=16000)()\n",
        "    audio_predictions = dict.fromkeys(columns)\n",
        "    audio_predictions[\"Audio Filename\"] = audio_filename\n",
        "\n",
        "    # Compute embeddings\n",
        "    embeddings_effnetDiscogs = embeddings_model_effnetDiscogs(audio)\n",
        "    embeddings_musiCNN = embeddings_model_musiCNN(audio)\n",
        "    embeddings_VGGish = embeddings_model_VGGish(audio)\n",
        "\n",
        "    # Run inference for all the models\n",
        "    feature_effnetDiscogs = embeddings_effnetDiscogs.reshape(-1, 1, 1, embeddings_effnetDiscogs.shape[1])\n",
        "    pool_deamEffnetDiscogs = Pool()\n",
        "    pool_deamEffnetDiscogs.set(input_layer_deamEffnetDiscogs, feature_effnetDiscogs)\n",
        "    predictions_deamEffnetDiscogs = av_deamEffnetDiscogs_model(pool_deamEffnetDiscogs)[output_layer_deamEffnetDiscogs].squeeze()\n",
        "    audio_predictions[\"Valence DEAM-Effnet-Discogs\"] = predictions_deamEffnetDiscogs.mean(axis=0)[0]\n",
        "    audio_predictions[\"Arousal DEAM-Effnet-Discogs\"] = predictions_deamEffnetDiscogs.mean(axis=0)[1]\n",
        "    pool_emomusicEffnetDiscogs = Pool()\n",
        "    pool_emomusicEffnetDiscogs.set(input_layer_emomusicEffnetDiscogs, feature_effnetDiscogs)\n",
        "    predictions_emomusicEffnetDiscogs = av_emomusicEffnetDiscogs_model(pool_emomusicEffnetDiscogs)[output_layer_emomusicEffnetDiscogs].squeeze()\n",
        "    audio_predictions[\"Valence EmoMusic-Effnet-Discogs\"] = predictions_emomusicEffnetDiscogs.mean(axis=0)[0]\n",
        "    audio_predictions[\"Arousal EmoMusic-Effnet-Discogs\"] = predictions_emomusicEffnetDiscogs.mean(axis=0)[1]\n",
        "\n",
        "    feature_musiCNN = embeddings_musiCNN.reshape(-1, 1, 1, embeddings_musiCNN.shape[1])\n",
        "    pool_deamMusiCNN = Pool()\n",
        "    pool_deamMusiCNN.set(input_layer_deamMusiCNN, feature_musiCNN)\n",
        "    predictions_deamMusiCNN = av_deamMusiCNN_model(pool_deamMusiCNN)[output_layer_deamMusiCNN].squeeze()\n",
        "    audio_predictions[\"Valence DEAM-MusiCNN\"] = predictions_deamMusiCNN.mean(axis=0)[0]\n",
        "    audio_predictions[\"Arousal DEAM-MusiCNN\"] = predictions_deamMusiCNN.mean(axis=0)[1]\n",
        "    pool_emomusicMusiCNN = Pool()\n",
        "    pool_emomusicMusiCNN.set(input_layer_emomusicMusiCNN, feature_musiCNN)\n",
        "    predictions_emomusicMusiCNN = av_emomusicMusiCNN_model(pool_emomusicMusiCNN)[output_layer_emomusicMusiCNN].squeeze()\n",
        "    audio_predictions[\"Valence EmoMusic-MusiCNN\"] = predictions_emomusicMusiCNN.mean(axis=0)[0]\n",
        "    audio_predictions[\"Arousal EmoMusic-MusiCNN\"] = predictions_emomusicMusiCNN.mean(axis=0)[1]\n",
        "\n",
        "    feature_VGGish = embeddings_VGGish.reshape(-1, 1, 1, embeddings_VGGish.shape[1])\n",
        "    pool_deamVGGish = Pool()\n",
        "    pool_deamVGGish.set(input_layer_deamVGGish, feature_VGGish)\n",
        "    predictions_deamVGGish = av_deamVGGish_model(pool_deamVGGish)[output_layer_deamVGGish].squeeze()\n",
        "    audio_predictions[\"Valence DEAM-VGGish\"] = predictions_deamVGGish.mean(axis=0)[0]\n",
        "    audio_predictions[\"Arousal DEAM-VGGish\"] = predictions_deamVGGish.mean(axis=0)[1]\n",
        "    pool_emomusicVGGish = Pool()\n",
        "    pool_emomusicVGGish.set(input_layer_emomusicVGGish, feature_VGGish)\n",
        "    predictions_emomusicVGGish = av_emomusicVGGish_model(pool_emomusicVGGish)[output_layer_emomusicVGGish].squeeze()\n",
        "    audio_predictions[\"Valence EmoMusic-VGGish\"] = predictions_emomusicVGGish.mean(axis=0)[0]\n",
        "    audio_predictions[\"Arousal EmoMusic-VGGish\"] = predictions_emomusicVGGish.mean(axis=0)[1]\n",
        "\n",
        "    # Append predictions of an audio recording to the Pandas DataFrame\n",
        "    df = df.append(audio_predictions, ignore_index = True)\n",
        "    num_audio += 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, let's save the resultant DataFrame in a .csv file."
      ],
      "metadata": {
        "id": "42ECj73rZdhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATAFRAME_FILENAME = \"dataframe_predictionsAV.csv\"   # Modify this according to your preferred path to save the .csv file\n",
        "df.to_csv(DATAFRAME_FILENAME)\n",
        "print('Saved DataFrame with {0} entries! {1}'.format(len(df), DATAFRAME_FILENAME))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOFh7rjj4-ni",
        "outputId": "b58f6363-fd0e-4dad-f18c-7c8bb01d4b23"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved DataFrame with 300 entries! dataframe_predictionsAV.csv\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "5YJRQecAZoY7",
        "VXZzAjzbblBL",
        "Y64_rQbQfspz"
      ],
      "name": "ComputeModelPredictions_AMPLAB_ArousalValenceAssignment_Betty.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}